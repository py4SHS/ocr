{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef557a74-6853-44a7-b94c-e8d8f48ba930",
   "metadata": {},
   "source": [
    "# OCR Lab\n",
    "\n",
    "## Main goals of this lab:\n",
    "- Call tesseract to apply OCR on an image\n",
    "- Apply some preprocessing to the source image to improve OCR performances\n",
    "- Evaluate the performances using some metrics to compare models\n",
    "\n",
    "Bonus:\n",
    "- Use tesseract to find word localisation\n",
    "\n",
    "## Prerequisites\n",
    "- install dependencies from the parent folder\n",
    "- have tesseract installed on your computer\n",
    "- put the carolinems.traindata in you tesseract folder: ``tesseract --list-langs``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed99497-3b25-42fd-bb66-f20689cc2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # CV2 is a library specialized in image processing\n",
    "import numpy as np\n",
    "import pytesseract # pytesseract is our interface to communicate with tesseract\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c489e68-1472-4f9c-9c1b-8fe984b02ae1",
   "metadata": {},
   "source": [
    "# Open the file as is and try OCR\n",
    "\n",
    "First we will try just to use the current image and see tesseract's result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f42f74e-6698-4e42-9b52-761b69ad99b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = Path('..') / 'demo_data'\n",
    "image_path = image_dir / 'demo_image.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7de562-aeca-4b32-b030-3d1bf1bbe296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image(image):\n",
    "    img = cv2.imread(image)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a151ac3-5937-4d96-b6f9-273a6206b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_image(image_path)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d87db6e-6fa0-47a6-90f7-f819ec51c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=pytesseract.image_to_string(img, lang=\"carolinems\") # the lang parameters allows to select the tesseract model to use \n",
    "print(\"The text is :\\n\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799906ab-580e-4a6f-9783-f362969f777e",
   "metadata": {},
   "source": [
    "Are we happy with the result ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1b2f3c-9b87-4a59-8d3e-1eeb9155e09f",
   "metadata": {},
   "source": [
    "# What preprocessing can be done ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e94ca3-f55b-4e87-b0d4-d7eba018414b",
   "metadata": {},
   "source": [
    "- Image preprocessing\n",
    "  * grayscaling\n",
    "  * thresholding\n",
    "  * dilating\n",
    "  * eroding\n",
    "  * opening\n",
    "  * canny edge detection\n",
    "  * noise removal\n",
    "  * template matching.\n",
    "- Orientation (deskwing)\n",
    "- Segmentation\n",
    "\n",
    "This list is not finite and can be easily extended"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f394f8-1750-4bd0-a42e-9b646f43240e",
   "metadata": {},
   "source": [
    "## Thresholding\n",
    "\n",
    "### Reminder on image\n",
    "An image is a 2D matrix of pixels. A pixel is composed in general of 3 components Red,Green,Blue (RGB) and any color can be obtained by the combinaison of those components. Each component can take any value from 0 to 255. https://rgbcolorpicker.com\n",
    "\n",
    "\n",
    "Thresholding is one of the first preprocessing to apply, it consists at :\n",
    "- first: transforming the image into grayscale\n",
    "- second: transform the image into black and white (and no gray) by applying a threshold on the grey intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ba28b6-48a0-4de1-9b2d-53da8bc7417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    ...\n",
    "\n",
    "def thresholding(image):\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1654e3ce-9994-4341-852c-cf117395048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = open_image(image_path)\n",
    "gray = get_grayscale(image)\n",
    "thresh = thresholding(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2aec54-c882-4b15-80b4-b32517511870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the two images to compare\n",
    "fig = plt.figure(figsize=(13,13))\n",
    "ax = []\n",
    "\n",
    "ax.append( fig.add_subplot(1, 2, 1) )\n",
    "ax[-1].set_title('Row text')\n",
    "b,g,r = cv2.split(image)\n",
    "rgb_img = cv2.merge([r,g,b])\n",
    "plt.imshow(rgb_img, cmap='gray')\n",
    "\n",
    "ax.append( fig.add_subplot(1, 2, 2) )\n",
    "ax[-1].set_title('After thresholding')\n",
    "plt.imshow(thresh, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b23184f-ffe8-405d-9dc6-76a09aaa2589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply tesseract again on the black and white image\n",
    "text=pytesseract.image_to_string(thresh, lang=\"carolinems\")\n",
    "print(\"The text is :\\n\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d03250-989a-4715-a7c9-37911fc2a822",
   "metadata": {},
   "source": [
    "## Other preprocessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a095b648-ec23-443f-ba5b-d0b30c1645d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5199c7-b9b1-416a-a9cd-76c67ca5c709",
   "metadata": {},
   "source": [
    "# OCR Evaluation\n",
    "\n",
    "To evaluate the performances of the OCR, we need a ``ground truth`` with the expected text.\n",
    "Then the ``jiwer`` (https://jitsi.github.io/jiwer/usage/) library can compute performance metrics by comparing the two texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f3207-da9e-4678-97e8-6c2f34e0c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(image_dir / \"ground_truth.txt\") as file:\n",
    "    ground_truth = file.readlines()\n",
    "\n",
    "ground_truth = \" \".join([ i.strip() for i in ground_truth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd0a34-df96-49f4-948a-4edaac42c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer\n",
    "\n",
    "def score(ground_truth, predicted):\n",
    "    output_words = jiwer.process_words(ground_truth, predicted)\n",
    "    output_char = jiwer.process_characters(ground_truth, predicted)\n",
    "    return {\n",
    "        \"wer\": output_words.wer,\n",
    "        \"cer\": output_char.cer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eb9e52-4c05-42b7-97de-e76e6f56154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get OCR output using Pytesseract\n",
    "lang = \"carolinems\"\n",
    "\n",
    "custom_config = r'--oem 3 --psm 1'\n",
    "print('-----------------------------------------')\n",
    "print('ORIGINAL IMAGE')\n",
    "print('-----------------------------------------')\n",
    "print(score(ground_truth, pytesseract.image_to_string(image, config=custom_config, lang=lang)))\n",
    "\n",
    "print('-----------------------------------------')\n",
    "print('IMAGE WITH THRESHOLDING')\n",
    "print('-----------------------------------------')\n",
    "print(score(ground_truth, pytesseract.image_to_string(thresh, config=custom_config, lang=lang)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a6ee35-e8fa-4b09-810f-b0c51d49d613",
   "metadata": {},
   "source": [
    "# Word localisation\n",
    "\n",
    "Tesseract can do more things than just outputting the raw text. Here we'll use it to find the coordinates of words: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbaa0b6-919c-4371-a136-49d034e07c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pytesseract import Output\n",
    "\n",
    "lang = \"carolinems\"\n",
    "custom_config = r'--oem 3 --psm 1'\n",
    "\n",
    "image = deepcopy(thresh)\n",
    "h, w = image.shape\n",
    "\n",
    "d = pytesseract.image_to_data(image, config=custom_config, output_type=Output.DICT, lang=lang)\n",
    "\n",
    "n_boxes = len(d['text'])\n",
    "for i in range(n_boxes):\n",
    "    # condition to only pick boxes with a confidence > 40%\n",
    "    if int(d['conf'][i]) > 40:\n",
    "        (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "        image = cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

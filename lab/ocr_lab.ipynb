{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef557a74-6853-44a7-b94c-e8d8f48ba930",
   "metadata": {},
   "source": [
    "# OCR Lab\n",
    "\n",
    "## Main goals of this lab:\n",
    "- Call tesseract to apply OCR on an image\n",
    "- Apply some preprocessing to the source image to improve OCR performances\n",
    "- Evaluate the performances using some metrics to compare models\n",
    "\n",
    "Bonus:\n",
    "- Use tesseract to find word localisation\n",
    "\n",
    "## Prerequisites\n",
    "- install dependencies from the parent folder\n",
    "- have tesseract installed on your computer\n",
    "- put the carolinems.traindata in you tesseract folder: ``tesseract --list-langs``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed99497-3b25-42fd-bb66-f20689cc2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # CV2 is a library specialized in image processing\n",
    "import numpy as np\n",
    "import pytesseract # pytesseract is our interface to communicate with tesseract\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c489e68-1472-4f9c-9c1b-8fe984b02ae1",
   "metadata": {},
   "source": [
    "# Open the file as is and try OCR\n",
    "\n",
    "First we will try just to use the current image and see tesseract's result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f42f74e-6698-4e42-9b52-761b69ad99b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = Path('..') / 'demo_data'\n",
    "image_path = image_dir / 'demo_image.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7de562-aeca-4b32-b030-3d1bf1bbe296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image(image):\n",
    "    img = cv2.imread(image)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a151ac3-5937-4d96-b6f9-273a6206b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_image(image_path)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d87db6e-6fa0-47a6-90f7-f819ec51c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/madmaze/pytesseract\n",
    "text=pytesseract.image_to_string(img, lang=\"carolinems\") # the lang parameters allows to select the tesseract model to use \n",
    "print(\"The text is :\\n\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799906ab-580e-4a6f-9783-f362969f777e",
   "metadata": {},
   "source": [
    "Are we happy with the result ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1b2f3c-9b87-4a59-8d3e-1eeb9155e09f",
   "metadata": {},
   "source": [
    "# What preprocessing can be done ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e94ca3-f55b-4e87-b0d4-d7eba018414b",
   "metadata": {},
   "source": [
    "- Image preprocessing\n",
    "  * grayscaling\n",
    "  * thresholding\n",
    "  * dilating\n",
    "  * eroding\n",
    "  * opening\n",
    "  * canny edge detection\n",
    "  * noise removal\n",
    "  * template matching.\n",
    "- Orientation (deskwing)\n",
    "- Segmentation\n",
    "\n",
    "This list is not finite and can be easily extended"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f394f8-1750-4bd0-a42e-9b646f43240e",
   "metadata": {},
   "source": [
    "## Thresholding\n",
    "\n",
    "### Reminder on image\n",
    "An image is a 2D matrix of pixels. A pixel is composed in general of 3 components Red,Green,Blue (RGB) and any color can be obtained by the combinaison of those components. Each component can take any value from 0 to 255. https://rgbcolorpicker.com\n",
    "\n",
    "\n",
    "Thresholding is one of the first preprocessing to apply, it consists at :\n",
    "- first: transforming the image into grayscale\n",
    "- second: transform the image into black and white (and no gray) by applying a threshold on the grey intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ba28b6-48a0-4de1-9b2d-53da8bc7417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1654e3ce-9994-4341-852c-cf117395048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = open_image(image_path)\n",
    "gray = ... # grey scaled image\n",
    "thresh = ... # thresholded image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2aec54-c882-4b15-80b4-b32517511870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the two images to compare\n",
    "fig = plt.figure(figsize=(13,13))\n",
    "ax = []\n",
    "\n",
    "ax.append( fig.add_subplot(1, 2, 1) )\n",
    "ax[-1].set_title('Row text')\n",
    "b,g,r = cv2.split(image)\n",
    "rgb_img = cv2.merge([r,g,b])\n",
    "plt.imshow(rgb_img, cmap='gray')\n",
    "\n",
    "ax.append( fig.add_subplot(1, 2, 2) )\n",
    "ax[-1].set_title('After thresholding')\n",
    "plt.imshow(thresh, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b23184f-ffe8-405d-9dc6-76a09aaa2589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply tesseract again on the black and white image\n",
    "text=...\n",
    "print(\"The text is :\\n\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d03250-989a-4715-a7c9-37911fc2a822",
   "metadata": {},
   "source": [
    "## Other preprocessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a095b648-ec23-443f-ba5b-d0b30c1645d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5199c7-b9b1-416a-a9cd-76c67ca5c709",
   "metadata": {},
   "source": [
    "# OCR Evaluation\n",
    "\n",
    "To evaluate the performances of the OCR, we need a ``ground truth`` with the expected text.\n",
    "Then the ``jiwer`` (https://jitsi.github.io/jiwer/usage/) library can compute performance metrics by comparing the two texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f3207-da9e-4678-97e8-6c2f34e0c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(image_dir / \"ground_truth.txt\") as file:\n",
    "    ground_truth = file.readlines()\n",
    "\n",
    "ground_truth = \" \".join([ i.strip() for i in ground_truth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd0a34-df96-49f4-948a-4edaac42c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer\n",
    "\n",
    "def score(ground_truth, predicted):\n",
    "    return {\n",
    "        \"wer\": ...,\n",
    "        \"cer\": ...\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eb9e52-4c05-42b7-97de-e76e6f56154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get OCR output using Pytesseract\n",
    "lang = \"carolinems\"\n",
    "\n",
    "custom_config = r'--oem 3 --psm 1'\n",
    "print('-----------------------------------------')\n",
    "print('ORIGINAL IMAGE')\n",
    "print('-----------------------------------------')\n",
    "print(score(ground_truth, pytesseract.image_to_string(image, config=custom_config, lang=lang)))\n",
    "\n",
    "print('-----------------------------------------')\n",
    "print('IMAGE WITH THRESHOLDING')\n",
    "print('-----------------------------------------')\n",
    "print(score(ground_truth, pytesseract.image_to_string(thresh, config=custom_config, lang=lang)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9f9e5-bbd7-4c98-9ad6-c0fd525e0073",
   "metadata": {},
   "source": [
    "# Tesseract parameters\n",
    "\n",
    "Tesseract can do thing for us but requires a tuning to be able to be adapted to our case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb70c95-6327-4342-8479-a7188e85c051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage:\n",
      "  tesseract --help | --help-extra | --help-psm | --help-oem | --version\n",
      "  tesseract --list-langs [--tessdata-dir PATH]\n",
      "  tesseract --print-fonts-table [options...] [configfile...]\n",
      "  tesseract --print-parameters [options...] [configfile...]\n",
      "  tesseract imagename|imagelist|stdin outputbase|stdout [options...] [configfile...]\n",
      "\n",
      "OCR options:\n",
      "  --tessdata-dir PATH   Specify the location of tessdata path.\n",
      "  --user-words PATH     Specify the location of user words file.\n",
      "  --user-patterns PATH  Specify the location of user patterns file.\n",
      "  --dpi VALUE           Specify DPI for input image.\n",
      "  --loglevel LEVEL      Specify logging level. LEVEL can be\n",
      "                        ALL, TRACE, DEBUG, INFO, WARN, ERROR, FATAL or OFF.\n",
      "  -l LANG[+LANG]        Specify language(s) used for OCR.\n",
      "  -c VAR=VALUE          Set value for config variables.\n",
      "                        Multiple -c arguments are allowed.\n",
      "  --psm NUM             Specify page segmentation mode.\n",
      "  --oem NUM             Specify OCR Engine mode.\n",
      "NOTE: These options must occur before any configfile.\n",
      "\n",
      "Page segmentation modes:\n",
      "  0    Orientation and script detection (OSD) only.\n",
      "  1    Automatic page segmentation with OSD.\n",
      "  2    Automatic page segmentation, but no OSD, or OCR. (not implemented)\n",
      "  3    Fully automatic page segmentation, but no OSD. (Default)\n",
      "  4    Assume a single column of text of variable sizes.\n",
      "  5    Assume a single uniform block of vertically aligned text.\n",
      "  6    Assume a single uniform block of text.\n",
      "  7    Treat the image as a single text line.\n",
      "  8    Treat the image as a single word.\n",
      "  9    Treat the image as a single word in a circle.\n",
      " 10    Treat the image as a single character.\n",
      " 11    Sparse text. Find as much text as possible in no particular order.\n",
      " 12    Sparse text with OSD.\n",
      " 13    Raw line. Treat the image as a single text line,\n",
      "       bypassing hacks that are Tesseract-specific.\n",
      "\n",
      "OCR Engine modes:\n",
      "  0    Legacy engine only.\n",
      "  1    Neural nets LSTM engine only.\n",
      "  2    Legacy + LSTM engines.\n",
      "  3    Default, based on what is available.\n",
      "\n",
      "Single options:\n",
      "  -h, --help            Show minimal help message.\n",
      "  --help-extra          Show extra help for advanced users.\n",
      "  --help-psm            Show page segmentation modes.\n",
      "  --help-oem            Show OCR Engine modes.\n",
      "  -v, --version         Show version information.\n",
      "  --list-langs          List available languages for tesseract engine.\n",
      "  --print-fonts-table   Print tesseract fonts table.\n",
      "  --print-parameters    Print tesseract parameters.\n"
     ]
    }
   ],
   "source": [
    "!tesseract --help-extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be5a0af-e9ee-4a58-a0ee-73399816cf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"carolinems\"\n",
    "\n",
    "for psm in ...:\n",
    "    custom_config = ...\n",
    "    print(f\"PSM: {psm}\", score(ground_truth, pytesseract.image_to_string(thresh, config=custom_config, lang=lang)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8b8c24-a88a-454e-b938-96c48e2e2a05",
   "metadata": {},
   "source": [
    "## PSM for Page segmentation modes\n",
    "\n",
    "It is the way Tesseract segment the image into lines. It has a huge impact on tesseract ability to detect text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a6ee35-e8fa-4b09-810f-b0c51d49d613",
   "metadata": {},
   "source": [
    "# Word localisation\n",
    "\n",
    "Tesseract can do more things than just outputting the raw text. Here we'll use it to find the coordinates of words: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbaa0b6-919c-4371-a136-49d034e07c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pytesseract import Output\n",
    "\n",
    "lang = \"carolinems\"\n",
    "custom_config = r'--oem 3 --psm 1'\n",
    "\n",
    "image = deepcopy(thresh)\n",
    "h, w = image.shape\n",
    "\n",
    "d = pytesseract.image_to_data(image, config=custom_config, output_type=Output.DICT, lang=lang)\n",
    "\n",
    "n_boxes = len(d['text'])\n",
    "for i in range(n_boxes):\n",
    "    # condition to only pick boxes with a confidence > 40%\n",
    "    if int(d['conf'][i]) > 40:\n",
    "        (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "        image = cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
